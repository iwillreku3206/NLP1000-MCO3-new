{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b2d22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6f9a57bf874e71b39fa67fb98285a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a2dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, M2M100ForConditionalGeneration, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM, NllbTokenizerFast\n",
    "from tokenization_small100 import SMALL100Tokenizer\n",
    "from peft import LoraModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0665ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c0df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "FAIRSEQ_LANGUAGE_CODES = ['ace_Arab', 'ace_Latn', 'acm_Arab', 'acq_Arab', 'aeb_Arab', 'afr_Latn', 'ajp_Arab', 'aka_Latn', 'amh_Ethi', 'apc_Arab', 'arb_Arab', 'ars_Arab', 'ary_Arab', 'arz_Arab', 'asm_Beng', 'ast_Latn', 'awa_Deva', 'ayr_Latn', 'azb_Arab', 'azj_Latn', 'bak_Cyrl', 'bam_Latn', 'ban_Latn', 'bel_Cyrl', 'bem_Latn', 'ben_Beng', 'bho_Deva', 'bjn_Arab', 'bjn_Latn', 'bod_Tibt', 'bos_Latn', 'bug_Latn', 'bul_Cyrl', 'cat_Latn', 'ceb_Latn', 'ces_Latn', 'cjk_Latn', 'ckb_Arab', 'crh_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'dik_Latn', 'dyu_Latn', 'dzo_Tibt', 'ell_Grek', 'eng_Latn', 'epo_Latn', 'est_Latn', 'eus_Latn', 'ewe_Latn', 'fao_Latn', 'pes_Arab', 'fij_Latn', 'fin_Latn', 'fon_Latn', 'fra_Latn', 'fur_Latn', 'fuv_Latn', 'gla_Latn', 'gle_Latn', 'glg_Latn', 'grn_Latn', 'guj_Gujr', 'hat_Latn', 'hau_Latn', 'heb_Hebr', 'hin_Deva', 'hne_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Armn', 'ibo_Latn', 'ilo_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jav_Latn', 'jpn_Jpan', 'kab_Latn', 'kac_Latn', 'kam_Latn', 'kan_Knda', 'kas_Arab', 'kas_Deva', 'kat_Geor', 'knc_Arab', 'knc_Latn', 'kaz_Cyrl', 'kbp_Latn', 'kea_Latn', 'khm_Khmr', 'kik_Latn', 'kin_Latn', 'kir_Cyrl', 'kmb_Latn', 'kon_Latn', 'kor_Hang', 'kmr_Latn', 'lao_Laoo', 'lvs_Latn', 'lij_Latn', 'lim_Latn', 'lin_Latn', 'lit_Latn', 'lmo_Latn', 'ltg_Latn', 'ltz_Latn', 'lua_Latn', 'lug_Latn', 'luo_Latn', 'lus_Latn', 'mag_Deva', 'mai_Deva', 'mal_Mlym', 'mar_Deva', 'min_Latn', 'mkd_Cyrl', 'plt_Latn', 'mlt_Latn', 'mni_Beng', 'khk_Cyrl', 'mos_Latn', 'mri_Latn', 'zsm_Latn', 'mya_Mymr', 'nld_Latn', 'nno_Latn', 'nob_Latn', 'npi_Deva', 'nso_Latn', 'nus_Latn', 'nya_Latn', 'oci_Latn', 'gaz_Latn', 'ory_Orya', 'pag_Latn', 'pan_Guru', 'pap_Latn', 'pol_Latn', 'por_Latn', 'prs_Arab', 'pbt_Arab', 'quy_Latn', 'ron_Latn', 'run_Latn', 'rus_Cyrl', 'sag_Latn', 'san_Deva', 'sat_Beng', 'scn_Latn', 'shn_Mymr', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'smo_Latn', 'sna_Latn', 'snd_Arab', 'som_Latn', 'sot_Latn', 'spa_Latn', 'als_Latn', 'srd_Latn', 'srp_Cyrl', 'ssw_Latn', 'sun_Latn', 'swe_Latn', 'swh_Latn', 'szl_Latn', 'tam_Taml', 'tat_Cyrl', 'tel_Telu', 'tgk_Cyrl', 'tgl_Latn', 'tha_Thai', 'tir_Ethi', 'taq_Latn', 'taq_Tfng', 'tpi_Latn', 'tsn_Latn', 'tso_Latn', 'tuk_Latn', 'tum_Latn', 'tur_Latn', 'twi_Latn', 'tzm_Tfng', 'uig_Arab', 'ukr_Cyrl', 'umb_Latn', 'urd_Arab', 'uzn_Latn', 'vec_Latn', 'vie_Latn', 'war_Latn', 'wol_Latn', 'xho_Latn', 'ydd_Hebr', 'yor_Latn', 'yue_Hant', 'zho_Hans', 'zho_Hant', 'zul_Latn']  # fmt: skip\n",
    "\n",
    "tokenizer = NllbTokenizerFast.from_pretrained(\"nllb-tgl-to-eng-seq2seq-model-v3\",\n",
    "                                                src_lang=\"tgl_Latn\",\n",
    "                                                tgt_lang=\"eng_Latn\",)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"nllb-tgl-to-eng-seq2seq-model-v3\", quantization_config=bnb_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa86b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight True\n",
      "model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight True\n",
      "model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight True\n",
      "model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight True\n",
      "model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight True\n",
      "model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight True\n",
      "model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.0.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.0.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.0.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.0.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.0.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.0.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.0.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.0.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.0.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.0.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.0.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.0.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.1.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.1.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.1.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.1.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.1.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.1.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.1.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.1.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.1.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.1.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.1.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.1.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.2.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.2.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.2.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.2.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.2.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.2.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.2.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.2.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.2.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.2.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.2.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.2.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.3.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.3.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.3.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.3.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.3.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.3.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.3.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.3.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.3.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.3.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.3.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.3.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.4.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.4.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.4.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.4.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.4.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.4.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.4.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.4.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.4.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.4.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.4.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.4.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.5.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.5.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.5.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.5.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.5.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.5.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.5.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.5.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.5.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.5.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.5.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.5.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.6.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.6.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.6.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.6.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.6.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.6.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.6.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.6.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.6.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.6.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.6.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.6.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.7.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.7.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.7.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.7.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.7.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.7.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.7.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.7.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.7.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.7.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.7.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.7.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.8.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.8.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.8.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.8.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.8.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.8.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.8.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.8.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.8.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.8.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.8.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.8.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.9.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.9.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.9.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.9.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.9.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.9.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.9.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.9.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.9.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.9.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.9.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.9.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.10.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.10.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.10.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.10.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.10.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.10.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.10.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.10.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.10.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.10.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.10.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.10.encoder_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.11.self_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.11.self_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.11.self_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.11.self_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.11.self_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.11.self_attn.q_proj.lora_B.default.weight True\n",
      "model.decoder.layers.11.encoder_attn.k_proj.lora_A.default.weight True\n",
      "model.decoder.layers.11.encoder_attn.k_proj.lora_B.default.weight True\n",
      "model.decoder.layers.11.encoder_attn.v_proj.lora_A.default.weight True\n",
      "model.decoder.layers.11.encoder_attn.v_proj.lora_B.default.weight True\n",
      "model.decoder.layers.11.encoder_attn.q_proj.lora_A.default.weight True\n",
      "model.decoder.layers.11.encoder_attn.q_proj.lora_B.default.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" in name.lower():\n",
    "        print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04ff0d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 616,843,264 || trainable%: 0.2869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rek\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\peft\\mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rek\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0396a939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac818017d241418b9209daf5042eec05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "tgl_eng = pd.read_csv(\"tagalog-to-english-corpora.csv\")\n",
    "\n",
    "def preprocess(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"language1_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        batch[\"language2_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "eval_df = tgl_eng.sample(frac=0.01, random_state=42)\n",
    "\n",
    "eval_dataset = datasets.Dataset.from_pandas(eval_df)\n",
    "\n",
    "eval_dataset_processed = eval_dataset.map(preprocess, batched=True, remove_columns=['language1_text', 'language2_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d32603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"training-nllb-tgl-to-english-v2-working\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1000,\n",
    "    logging_first_step=True,\n",
    "    report_to=\"none\",\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37301673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rek\\AppData\\Local\\Temp\\ipykernel_33572\\2512045289.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=None,\n",
    "    eval_dataset=eval_dataset_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d19b0d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 10.6953125,\n",
       " 'eval_model_preparation_time': 0.0034,\n",
       " 'eval_bleu': 29.8538,\n",
       " 'eval_gen_len': 34.6301,\n",
       " 'eval_runtime': 166.4204,\n",
       " 'eval_samples_per_second': 1.755,\n",
       " 'eval_steps_per_second': 0.114}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d4185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"Pumunta si Roan sa Quezon City noong Lunes.\", return_tensors=\"pt\").to(model.device)\n",
    "translated_tokens = model.generate(\n",
    "    **tokens, forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"eng_Latn\"), max_length=30,\n",
    ")\n",
    "text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f2f5640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roan went to Quezon City on Monday.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
