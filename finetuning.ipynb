{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a62792e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5183230b593466db8c69a29285420c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "103694d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, M2M100ForConditionalGeneration, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM, NllbTokenizerFast\n",
    "from tokenization_small100 import SMALL100Tokenizer\n",
    "from peft import LoraModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485fa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f64b07b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "FAIRSEQ_LANGUAGE_CODES = ['ace_Arab', 'ace_Latn', 'acm_Arab', 'acq_Arab', 'aeb_Arab', 'afr_Latn', 'ajp_Arab', 'aka_Latn', 'amh_Ethi', 'apc_Arab', 'arb_Arab', 'ars_Arab', 'ary_Arab', 'arz_Arab', 'asm_Beng', 'ast_Latn', 'awa_Deva', 'ayr_Latn', 'azb_Arab', 'azj_Latn', 'bak_Cyrl', 'bam_Latn', 'ban_Latn', 'bel_Cyrl', 'bem_Latn', 'ben_Beng', 'bho_Deva', 'bjn_Arab', 'bjn_Latn', 'bod_Tibt', 'bos_Latn', 'bug_Latn', 'bul_Cyrl', 'cat_Latn', 'ceb_Latn', 'ces_Latn', 'cjk_Latn', 'ckb_Arab', 'crh_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'dik_Latn', 'dyu_Latn', 'dzo_Tibt', 'ell_Grek', 'eng_Latn', 'epo_Latn', 'est_Latn', 'eus_Latn', 'ewe_Latn', 'fao_Latn', 'pes_Arab', 'fij_Latn', 'fin_Latn', 'fon_Latn', 'fra_Latn', 'fur_Latn', 'fuv_Latn', 'gla_Latn', 'gle_Latn', 'glg_Latn', 'grn_Latn', 'guj_Gujr', 'hat_Latn', 'hau_Latn', 'heb_Hebr', 'hin_Deva', 'hne_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Armn', 'ibo_Latn', 'ilo_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jav_Latn', 'jpn_Jpan', 'kab_Latn', 'kac_Latn', 'kam_Latn', 'kan_Knda', 'kas_Arab', 'kas_Deva', 'kat_Geor', 'knc_Arab', 'knc_Latn', 'kaz_Cyrl', 'kbp_Latn', 'kea_Latn', 'khm_Khmr', 'kik_Latn', 'kin_Latn', 'kir_Cyrl', 'kmb_Latn', 'kon_Latn', 'kor_Hang', 'kmr_Latn', 'lao_Laoo', 'lvs_Latn', 'lij_Latn', 'lim_Latn', 'lin_Latn', 'lit_Latn', 'lmo_Latn', 'ltg_Latn', 'ltz_Latn', 'lua_Latn', 'lug_Latn', 'luo_Latn', 'lus_Latn', 'mag_Deva', 'mai_Deva', 'mal_Mlym', 'mar_Deva', 'min_Latn', 'mkd_Cyrl', 'plt_Latn', 'mlt_Latn', 'mni_Beng', 'khk_Cyrl', 'mos_Latn', 'mri_Latn', 'zsm_Latn', 'mya_Mymr', 'nld_Latn', 'nno_Latn', 'nob_Latn', 'npi_Deva', 'nso_Latn', 'nus_Latn', 'nya_Latn', 'oci_Latn', 'gaz_Latn', 'ory_Orya', 'pag_Latn', 'pan_Guru', 'pap_Latn', 'pol_Latn', 'por_Latn', 'prs_Arab', 'pbt_Arab', 'quy_Latn', 'ron_Latn', 'run_Latn', 'rus_Cyrl', 'sag_Latn', 'san_Deva', 'sat_Beng', 'scn_Latn', 'shn_Mymr', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'smo_Latn', 'sna_Latn', 'snd_Arab', 'som_Latn', 'sot_Latn', 'spa_Latn', 'als_Latn', 'srd_Latn', 'srp_Cyrl', 'ssw_Latn', 'sun_Latn', 'swe_Latn', 'swh_Latn', 'szl_Latn', 'tam_Taml', 'tat_Cyrl', 'tel_Telu', 'tgk_Cyrl', 'tgl_Latn', 'tha_Thai', 'tir_Ethi', 'taq_Latn', 'taq_Tfng', 'tpi_Latn', 'tsn_Latn', 'tso_Latn', 'tuk_Latn', 'tum_Latn', 'tur_Latn', 'twi_Latn', 'tzm_Tfng', 'uig_Arab', 'ukr_Cyrl', 'umb_Latn', 'urd_Arab', 'uzn_Latn', 'vec_Latn', 'vie_Latn', 'war_Latn', 'wol_Latn', 'xho_Latn', 'ydd_Hebr', 'yor_Latn', 'yue_Hant', 'zho_Hans', 'zho_Hant', 'zul_Latn']  # fmt: skip\n",
    "\n",
    "tokenizer = NllbTokenizerFast.from_pretrained(\"facebook/nllb-200-distilled-600M\",\n",
    "                                                src_lang=\"eng_Latn\",\n",
    "                                                tgt_lang=\"bicol\",)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", quantization_config=bnb_config)\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ['bicol']}, replace_additional_special_tokens=False)\n",
    "\n",
    "#tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a89765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 616,843,264 || trainable%: 0.2869\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b80da49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"How is you day today?\", return_tensors=\"pt\").to(model.device)\n",
    "translated_tokens = model.generate(\n",
    "    **tokens, forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"tgl_Latn\"), max_length=30,\n",
    ")\n",
    "text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c8464a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kumusta ka sa araw ngayon?']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46495d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c9012213d54580b795c434410fb038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d47e2bc15b40e095e04a2d8789a84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "parallel_corpora = pd.read_csv(\"english-to-bicol-corpora.csv\")\n",
    "\n",
    "def preprocess(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"language1_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        \n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        batch[\"language2_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "corpora = parallel_corpora.sample(frac=1, random_state=42)\n",
    "train_df = corpora.sample(frac=0.99, random_state=42)\n",
    "eval_df = corpora.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "train_dataset = datasets.Dataset.from_pandas(train_df)\n",
    "eval_dataset = datasets.Dataset.from_pandas(eval_df)\n",
    "\n",
    "train_dataset_processed = train_dataset.map(preprocess, batched=True, remove_columns=['language1_text', 'language2_text'])\n",
    "eval_dataset_processed = eval_dataset.map(preprocess, batched=True, remove_columns=['language1_text', 'language2_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07057887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"trained-nllb-en-to-bicol\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    logging_first_step=True,\n",
    "    report_to=\"none\",\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d33539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rek\\AppData\\Local\\Temp\\ipykernel_26412\\4143228653.py:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "gl_eval_pred = None\n",
    "\n",
    "#def compute_metrics(eval_pred):\n",
    "#    logits, labels = eval_pred\n",
    "#    # If logits are None (some eval configurations), return empty dict\n",
    "#    if logits is None:\n",
    "#        return {}\n",
    "#    # Convert logits to predicted token ids. Logits may be (batch, seq, vocab)\n",
    "#    preds = np.argmax(logits, axis=-1)\n",
    "#    labels = np.array(labels)\n",
    "#    labels_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "#    preds = np.array(preds)\n",
    "#    # Mask out label padding (we use -100 for padding labels). Only keep positions where label != -100\n",
    "#    mask = labels != -100\n",
    "#    if mask.sum() == 0:\n",
    "#        return {}\n",
    "#    preds_flat = preds[mask]\n",
    "#    labels_flat = labels[mask]\n",
    "#\n",
    "#    pred_str = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#    bleu = bleu.compute(predictions=pred_str, references=[[l] for l in labels_str])\n",
    "#    return {\n",
    "#        \"accuracy\": metric.compute(predictions=preds_flat.astype(np.int32), references=labels_flat.astype(np.int32)),\n",
    "#        \"bleu\": bleu[\"bleu\"],\n",
    "#    }\n",
    "\n",
    "gl_decoded_preds = None\n",
    "gl_decoded_labels = None\n",
    "gl_eval_preds = None\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    global gl_eval_preds\n",
    "    gl_eval_preds = eval_preds\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.tolist()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.tolist()\n",
    "    # Convert token IDs to text\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    global gl_decoded_preds, gl_decoded_labels\n",
    "    gl_decoded_preds = decoded_preds\n",
    "    gl_decoded_labels = decoded_labels\n",
    "\n",
    "    # sacrebleu expects list of predictions, list of list of references\n",
    "    result = bleu.compute(predictions=decoded_preds,\n",
    "                            references=[[l] for l in decoded_labels])\n",
    "    gl_eval_preds = result\n",
    "    return {\"bleu\": result[\"bleu\"]}\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_processed,\n",
    "    eval_dataset=eval_dataset_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "401d2637",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PeftModelForSeq2SeqLM:\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rek\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2300\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resume_from_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2299\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fsdp_enabled:\n\u001b[32m-> \u001b[39m\u001b[32m2300\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2301\u001b[39m     \u001b[38;5;66;03m# In case of repeating the find_executable_batch_size, set `self._train_batch_size` properly\u001b[39;00m\n\u001b[32m   2302\u001b[39m     state = TrainerState.load_from_json(os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rek\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:3021\u001b[39m, in \u001b[36mTrainer._load_from_checkpoint\u001b[39m\u001b[34m(self, resume_from_checkpoint, model)\u001b[39m\n\u001b[32m   3019\u001b[39m         model.set_adapter(active_adapter)\n\u001b[32m   3020\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3021\u001b[39m         \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_adapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_trainable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3022\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3023\u001b[39m     logger.warning(\n\u001b[32m   3024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe intermediate checkpoints of PEFT may not be saved correctly, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3025\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconsider using a custom callback to save \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mADAPTER_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in corresponding saving folders. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCheck some examples here: https://github.com/huggingface/peft/issues/96\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3027\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rek\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\peft\\peft_model.py:1368\u001b[39m, in \u001b[36mPeftModel.load_adapter\u001b[39m\u001b[34m(self, model_id, adapter_name, is_trainable, torch_device, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, key_mapping, **kwargs)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;66;03m# load the weights into the model\u001b[39;00m\n\u001b[32m   1367\u001b[39m ignore_mismatched_sizes = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mignore_mismatched_sizes\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m load_result = \u001b[43mset_peft_model_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43madapters_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1376\u001b[39m tuner = \u001b[38;5;28mself\u001b[39m.peft_config[adapter_name].peft_type\n\u001b[32m   1377\u001b[39m tuner_prefix = PEFT_TYPE_TO_PREFIX_MAPPING.get(tuner, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rek\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\peft\\utils\\save_and_load.py:565\u001b[39m, in \u001b[36mset_peft_model_state_dict\u001b[39m\u001b[34m(model, peft_model_state_dict, adapter_name, ignore_mismatched_sizes, low_cpu_mem_usage)\u001b[39m\n\u001b[32m    563\u001b[39m             module._move_adapter_to_device_of_base_layer(adapter_name)\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     load_result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_model_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_prompt_learning:\n\u001b[32m    568\u001b[39m     model.prompt_encoder[adapter_name].embedding.load_state_dict(\n\u001b[32m    569\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m: peft_model_state_dict[\u001b[33m\"\u001b[39m\u001b[33mprompt_embeddings\u001b[39m\u001b[33m\"\u001b[39m]}, strict=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    570\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rek\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for PeftModelForSeq2SeqLM:\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.6.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.7.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.8.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.9.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.10.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.self_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.k_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.k_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.v_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.v_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.q_proj.lora_A.default.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n\tsize mismatch for base_model.model.model.decoder.layers.11.encoder_attn.q_proj.lora_B.default.weight: copying a param with shape torch.Size([1024, 4]) from checkpoint, the shape in current model is torch.Size([1024, 8])."
     ]
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276365fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"nllb-en-to-bicol-seq2seq-model\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens = trainer.model.generate(**tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
